output.lm
output.aov<-aov(YIELD~VARIETY, data = lentils)
summary(output.aov)
output.aov<-aov(YIELD~VARIETY, data = lentils)      #ANOVA option 2 (gives the same result)
summary(output.aov)
remove(output.1m)
output.2m<-anova(lm(YIELD~VARIETY*FARM,data=lentils))
output.2m
output2.aov<-aov(YIELD~VARIETY*FARM, data=lentils)
summary(output2.aov)
TukeyHSD(aov(YIELD~FARM*VARIETY,data = lentils))
#Can also observe the interaction visually with an interaction plot
interaction.plot(lentils$FARM,lentils$VARIETY,lentils$YIELD)
#Across Varieties
interaction.plot(lentils$VARIETY,lentils$FARM,lentils$YIELD)
#Across Farms
interaction.plot(lentils$FARM,lentils$VARIETY,lentils$YIELD)
data.F1<-filter(lentils, FARM=="Farm1")
data.F1<-filter(lentils, FARM=="Farm1")
data,F1$NITROGEN = c(2.2, 3.4, 1.9, 4.3, 3.8, 1.1 4.9, 2.5, 5.7, 1.0, 3.2, 2.0)
data,F1$NITROGEN = c(2.2, 3.4, 1.9, 4.3, 3.8, 1.1, 4.9, 2.5, 5.7, 1.0, 3.2, 2.0)
data.F1$NITROGEN = c(2.2, 3.4, 1.9, 4.3, 3.8, 1.1, 4.9, 2.5, 5.7, 1.0, 3.2, 2.0)
data.F1$BLOCK=c("B2","B3","B1","B4","B3","B1","B4","B2","B4","B1","B3","B2")
#Determining the effect of a covariate
summary(aov(YIELD~VARIETY, data=data.F1))
summary(aov(YIELD~VARIETY+NITROGEN,data=data.F1))
aov??
??aov
summary(aov(YIELD~VARIETY, data = data.F1))
summary(aov(YIELD~VARIETY+BLOCK, data = data.F1))
str(lentils)
#Build a boxplot of YIELD by VARIETY (checking the distribution of the data - normal?)
ggplot(lentils, aes(x=VARIETY, y=HEIGHT))+ geom_boxplot()+
scale_x_discrete(name="Lentil Variety")
library("ggplot2")
library("dplyr")
library("tidyr")
#Build a boxplot of YIELD by VARIETY (checking the distribution of the data - normal?)
ggplot(lentils, aes(x=VARIETY, y=HEIGHT))+ geom_boxplot()+
scale_x_discrete(name="Lentil Variety")
#Build boxplot of YIELD by SITE
ggplot(lentils, aes(x=SITE, y=HEIGHT))+ geom_boxplot()+
scale_x_discrete(name="Planting Site")
#Shapiro Test - investigating the normality
shapiro.test(lentils$HEIGHT[lentils$VARIETY=="A"])
shapiro.test(lentils$HEIGHT[lentils$VARIETY=="C"])
#Shapiro Test - investigating the normality
shapiro.test(lentils$HEIGHT[lentils$VARIETY=="A"])
shapiro.test(lentils$HEIGHT[lentils$VARIETY=="B"])
shapiro.test(lentils$HEIGHT[lentils$VARIETY=="C"])
#Comparison of the t-test with its non-parametric equivalent --> Wilcoxon
lentils.x<-filter(lentils,SITE=="xeric")
#Compare results from one sample t-test and Wilcoxon
t.test(lentils.x$HEIGHT, mu=0.46, alternative = "two-sided")
#Compare results from one sample t-test and Wilcoxon
t.test(lentils.x$HEIGHT, mu=0.46, alternative = "two.sided")
wilcox.test(lentils.x$HEIGHT, mu=0.46, alternative = "two.sided")
#Running Mann-Whitney(Wilxocon)
#subset the data so you can compare the two groups --> lentils.x and lentils.m
lentils.m<-filter(lentils,SITE=="mesic")
t.test(lentils.x$HEIGHT,lentils.m$HEIGHT)
wilcox.test(lentils.x$HEIGHT,lentils.m$HEIGHT)
wilcox.test(lentils.x$HEIGHT,lentils.m$HEIGHT) #cannot compute exact p-value with ties
ks.test(lentils.x$HEIGHT, lentils.m$HEIGHT)
#For two sample, one-tailed test
ks.test(lentils.x$HEIGHT, lentils.m$HEIGHT, alternative = "greater")
#Kruskal-Wallis - non-parametric equivalent of the one-way ANOVA
kruskal.test(HEIGHT~VARIETY, data=lentils)
#Can compare these results to the parametric ANOVA
summary(aov(HEIGHT~VARIETY, data=lentils))
#Since there are multiple treatments, we need to follow-up with pair-wise Wilcoxon
#We are making multiple comparisons --> we need to adjust the p-value
VarA<-filter(lentils, VARIETY=="A")
VarB<-filter(lentils, VARIETY=="B")
VarC<-filter(lentils, VARIETY=="C")
wilcox.test(VarA$HEIGHT, VarB$HEIGHT, alternative = "two.sided")
wilcox.test(VarA$HEIGHT, VarC$HEIGHT, alternative = "two.sided")
wilcox.test(VarB$HEIGHT, VarC$HEIGHT, alternative = "two.sided")
#We are making multiple comparisons --> we need to adjust the p-value
p.adjust(c(1, 0.09265, 0.0001554), method ="bonferroni", n=3)
0.0001554*3
library("ggplot2")
library("dplyr")
library("tidyr")
library("dplyr", lib.loc="~/R/win-library/3.5")
library("dplyr")
#install needed packages for Non-parametric testing
install.packages("ggplot2", "dplyr", "tidyr")
install.packages("ggplot2", "dplyr", "tidyr")
install.packages("ggplot2", "dplyr", "tidyr")
install.packages("ggplot2", "dplyr", "tidyr")
install.packages("ggplot2", "dplyr", "tidyr")
library("ggplot2")
library("dplyr")
library("tidyr")
#Permutation Testing
#Permutation Analysis of Variance
anova(lm(YIELD~FARM*VARIETY,data=lentils))
#run the permutational ANOVA
install.packages("lmPerm")
library(lmPerm)
summary(aov(YIELD~FARM*VARIETY,data=lentils, seqs=T))
summary(aovp(YIELD~FARM*VARIETY,data=lentils, seqs=T))
#follow-up with pairwise comparisons
output3.p<-aovp(YIELD~FARM*VARIETY,data=lentils, seqs = T)
TukeyHSD(output3.p)
#load up data on lentil survival
lentils.s<-read.csv("lentils_survival.csv", header = T, na.strings = "")
head(lentils)
tail(lentils.s)
str(lentils.s)
#load up pertinent packages - dplyr and tidyr
install.packages("dplyr", "tidyr")
library(dplyr)
library(tidyr)
#Assign groups to the data
lentils.s<-group_by(lentils.s, VARIETY)
head(lentils)
str(lentils.s)
non.linear<-read.csv("non_linear.csv", header = T, na.strings = "")
head(non.linear)
#install packages
install.packages("ggplot2", "tidyr", "dplyr")
library(ggplot2)
library(tidyr)
library(dplyr)
install.packages("ggplot2")
library(dplyr)
library(tidyr)
library(dplyr)
graphics.off
ggplot(data=lentils, aes(x=SITE,y=HEIGHT)) +geom_boxplot()
ggplot(data=lentils, aes(x=SITE,y=HEIGHT)) +geom_boxplot()
ggplot(data=lentils, aes(x=SITE,y=HEIGHT)) + geom_boxplot()
ggplot_build(data=lentils, aes(x=SITE,y=HEIGHT)) + geom_boxplot()
library("ggplot2", lib.loc="~/R/win-library/3.5")
ggplot(data=lentils, aes(x=SITE,y=HEIGHT)) + geom_boxplot()
#may also test for outliers statistically
install.packages("outliers")
library(outlier)
library(outliers)
chisq.out.test(lentils.m$HEIGHT, variance=var(lentils.m$HEIGHT), opposite = TRUE)
chisq.out.test(lentils.m$HEIGHT, variance=var(lentils.m$HEIGHT), opposite = FALSE)
ggplot(data=lentils.m, aes(x=SITE,y=HEIGHT)) + geom_boxplot()
ggplot(data=lentils.x, aes(x=SITE,y=HEIGHT)) + geom_boxplot()
ggplot(data=lentils, aes(x=SITE,y=HEIGHT)) + geom_boxplot()
step(lm(YIELD~HEIGHT+DENSITY+FERTILIZER, data=lentils), direction = "backward")
step(lm(YIELD~HEIGHT+DENSITY+FERTILIZER, data=lentils), direction = "forward")
step(lm(YIELD~HEIGHT+DENSITY+FERTILIZER, data=lentils), direction = "both")
?step
install.packages("minpack.lm")
library(minpack.lm)
#non-linear
nlsLM(Y1~aPV^b, data=lentils)
View(non.linear)
#non-linear
nlsLM(Y1~aPV^b, data=non.linear)
#non-linear
nlsLM(Y1~a*PV^b, data=non.linear)
nlsLM(Y1~a*PV^b, data=non.linear, start = list(a=1,b=2) #including start values
#non-linear regression - log curve
nlsLM(Y1~a*PV^b, data=non.linear) # without starting values (error)
nlsLM(Y1~a*PV^b, data=non.linear, start = list(a=1,b=2) #including start values
nlsLM(Y1~a*PV^b, data=non.linear, start = list(a=1,b=2) #including start values
nlsLM(Y1~a*PV^b, data=non.linear, start = list(a=1,b=2)) #including start values
#non-linear regression - log curve
nlsLM(Y1~a*PV^b, data=non.linear) # without starting values (error)
nlsLM(Y1~a*PV^b, data=non.linear, start = list(a=1,b=2)) #including start values
#check if the produced curve fits your data visually
graphics.off
#check if the produced curve fits your data visually
log.curve(<-function(x)0.8896*x^1.9539)
#check if the produced curve fits your data visually
log.curve<-function(x)0.8896*x^1.9539)
#check if the produced curve fits your data visually
log.curve<-function(x)0.8896*x^1.9539
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) +geom_point()
+ StatFunction
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) +geom_point()+ StatFunction
library(ggplot)
library(ggplot2)
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) +geom_point()+ StatFunction
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) +geom_point() + StatFunction(fun=log.curve,color = "blue", size ="1")
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) +geom_point() + StatFunction(fun=log.curve,color = "blue", size =1)
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) +geom_point() +
StatFunction(fun=log.curve,color = "blue", size =1)
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) +geom_point() +
Stat_Function(fun=log.curve,color = "blue", size =1)
library("dplyr", lib.loc="~/R/win-library/3.5")
library("tidyr", lib.loc="~/R/win-library/3.5")
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) + geom_point() +
Stat_Function(fun=log.curve,color = "blue", size =1)
detach("package:ggplot2", unload=TRUE)
library("ggplot2", lib.loc="~/R/win-library/3.5")
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) + geom_point() +
Stat_Function(fun=log.curve,color = "blue", size =1)
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) + geom_point() +
Stat_Function(fun=log.curve,color = "blue", size =1)
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) + geom_point()
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) + geom_point() + Stat_Function(fun=log.curve,color = "blue", size =1)
#check if the produced curve fits your data visually
log.curve<-function(x)0.8896*x^1.9539 #create the function
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) + geom_point() + Stat_Function(fun = log.curve,color = "blue", size =1)
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) + geom_point() +
Stat_Function(fun = log.curve,color = "blue", size =1)
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) + geom_point() +
stat_function(fun = log.curve,color = "blue", size =1)
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) + geom_point() +
stat_function(fun = log.curve,color = "blue", size =1)
library(ggplot2)
library(tidyr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(dplyr)
#plot the data and the curve
ggplot(non.linear,aes(x=PV,y=Y1)) + geom_point() +
stat_function(fun = log.curve,color = "blue", size =1)
#Use AIC to evaluate the fit of a non-linear model (R2 values not appropriate)
View(non.linear)
#Use AIC to evaluate the fit of a non-linear model (R2 values not appropriate)
AIC(nlsLM(Y1~a*PV^b, data = non.linear, start = (a=1,b=2)))
#Use AIC to evaluate the fit of a non-linear model (R2 values not appropriate)
AIC(nlsLM(Y1~a*PV^b, data = non.linear, start = (a=1,b=2)))
#Use AIC to evaluate the fit of a non-linear model (R2 values not appropriate)
AIC(nlsLM(Y1~a*PV^b, data = non.linear, start = list(a=1,b=2)))
library(minpack.lm)
(nlsLM(Y1~a*PV^b, data = non.linear, start = list(a=1,b=2)))
AIC(nlsLM(Y1~a+b*PV^c, data = non.linear, start = list(a=0,b=1,c=2)))
AIC(nlsLM(Y1~a+b*PV, data = non.linear, start = list(a=0,b=1)))
#Use AIC to evaluate the fit of a non-linear model (R2 values not appropriate)
AIC(nlsLM(Y1~a*PV^b, data = non.linear, start = list(a=1,b=2))) #Log model
#"glm" function is preferred over "lm"
#build a logistic regression model
lr.model<-glm(SURVIVE~NITROGEN+PHOSPHORUS, data = lentils.s, family = "binomial")
summary(lr.model)
#we can use a step-wise comparison to identify the model fit (AIC)
step(glm(SURVIVE~NITROGEN+PHOSPHORUS, data = lentils.s, family = "binomial"))
#can also add interactions to your logistic model
lr.model2<-glm(SURVIVE~NITROGEN*PHOSPHORUS, data = lentils.s, family = "binomial")
summary(lr.model2)
#we can also use logistic regression to determine the odds ratio
#using a logistic model considering only nitrogen
lr.model.n<-glm(SURVIVE~NITROGEN, data = lentils.s, family = "binomial")
summary(lr.model.n)
#odds ratio
exp(coef(lr.model.n))
data("USArrests")
head("USArrests")
head(USArrests)
tail
tail(USArrests)
str(USArrests)
data("iris")
heda(iris)
head(iris)
tails(iris)
tail(iris)
str(iris)
PCAoutput1<-princomp(USArrests, cor = T)
#Output from the PCA
PCAoutput1$loadings
PCAoutput1$scores
summary(PCAoutput1)
eigen(cor(USArrests))
eigen(cor(USArrests))$values
eigen(cor(USArrests))$values/4
#PCA biplot to visualize the rotated points
biplot(PCAoutput1, choices = c(1,2))
#PCA biplot to visualize the rotated points
biplot(PCAoutput1, choices = c(1,3))
#PCA biplot to visualize the rotated points
biplot(PCAoutput1, choices = c(1,4))
#PCA biplot to visualize the rotated points
biplot(PCAoutput1, choices = c(1,2))
#Output from the PCA
PCAoutput1$loadings     #correlations with the original variables
PCAoutput1$scores       #new coordinate points after rotation
summary(PCAoutput1)     #variance explained by the components
eigen(cor(USArrests))   #eigenvalues
eigen(cor(USArrests))$values/4    #variance explained by eigenvalues
plot(PCAoutput1, choices = c(1,2))
PCAcolors <- c("#66c2a5","#fc8d62","#8da0cb")[as.integer(vint)]
PCAcolors <- c("#66c2a5","#fc8d62","#8da0cb")[as.integer(PCAoutput1)]
PCAcolors <- c("#66c2a5","#fc8d62","#8da0cb")[is.integer(PCAoutput1)]
par(mfrow=c(1,2))
plot(PCAoutput1[,1:2], # x and y data
pch=21,           # point shape
col=PCAcolors,    # point border color
bg=PCAcolors,     # point color
cex=1.5,          # point size
main="Scores")   # title of plot
plot(PCAoutput1[1,2], # x and y data
pch=21,           # point shape
col=PCAcolors,    # point border color
bg=PCAcolors,     # point color
cex=1.5,          # point size
main="Scores")   # title of plot
plot(PCAoutput1[comp 1,comp 2],  # x and y data
pch=21,           # point shape
col=PCAcolors,    # point border color
bg=PCAcolors,     # point color
cex=1.5,          # point size
main="Scores")   # title of plot
head(PCAoutput1)
plot(PCAoutput1[comp.1,comp.2],  # x and y data
pch=21,           # point shape
col=PCAcolors,    # point border color
bg=PCAcolors,     # point color
cex=1.5,          # point size
main="Scores")   # title of plot
plot(PCAoutput1[Comp.1,Comp.2],  # x and y data
pch=21,           # point shape
col=PCAcolors,    # point border color
bg=PCAcolors,     # point color
cex=1.5,          # point size
main="Scores")   # title of plot
plot(PCAoutput1[1:2],  # x and y data
pch=21,           # point shape
col=PCAcolors,    # point border color
bg=PCAcolors,     # point color
cex=1.5,          # point size
main="Scores")   # title of plot
graphics.off
graphics.off
#PCA biplot to visualize the rotated points
biplot(PCAoutput1, choices = c(1,2))
autoplot(prcomp(PCAoutput1))
library("ggplot2", lib.loc="~/R/win-library/3.5")
autoplot(prcomp(PCAoutput1))
library(ggfortify)
list(USArrests)
autoplot(prcomp(PCAoutput1))
install.packages(ggfortify)
head(iris)
autoplot(PCAoutput1, label = TRUE, label.size = 3,
loadings = TRUE, loadings.label = TRUE, loadings.label.size  = 3)
autoplot(USArrests, label = TRUE, label.size = 3,
loadings = TRUE, loadings.label = TRUE, loadings.label.size  = 3)
#PCA biplot to visualize the rotated points
biplot(PCAoutput1, choices = c(1,2))
#PCA biplot to visualize the rotated points
biplot(PCAoutput1, choices = c(1,2))
#Discmriminant Analysis
install.packages("candisc")
library(candisc)
View(iris)
list(iris)
out2=candisc(x,term="Species")
output.2m=candisc(x,term="Species")
x=lm(cbind(Petal.Length,Sepal.Length,Petal.Width,Sepal.Width)~Species,data = iris)
out=candisc(x,term="Species")
remove(out)
out2=candisc(x,term="Species")
install.packages(c("clipr", "rlang"))
summary(out2)
out2$structure #discriminant loadings
plot(out2,which=c(1,2), scale=8, var.col="#777777", var.lwd=1,col=c("red","green","blue"))
plot(out2,which=c(1,2), scale=8, var.col="#777777", var.lwd=1,
col=c("red","green","blue"))
#Discmriminant Analysis
install.packages("candisc")
library(candisc)
data("USArrests")
library("car", lib.loc="~/R/win-library/3.5")
library("candisc", lib.loc="~/R/win-library/3.5")
plot(out2,which=c(1,2), scale=8, var.col="#777777", var.lwd=1,
col=c("red","green","blue"))
library("ggplot2", lib.loc="~/R/win-library/3.5")
install.packages(rlang)
install.packages("rlang")
library(candisc)
install.packages("dplyr")
install.packages(plyr)
install.packages("plyr")
install.packages("plyr")
library(rlang)
library(dplyr)
library(plyr)
library(candisc)
library("candisc", lib.loc="~/R/win-library/3.5")
plot(out2,which=c(1,2), scale=8, var.col="#777777", var.lwd=1,
col=c("red","green","blue"))
graphics.off()
plot(out2,which=c(1,2), scale=8, var.col="#777777", var.lwd=1,
col=c("red","green","blue"))
summary(out2)
out2$structure #discriminant loadings
install.packages("rlang","dplyr","plyr","candisc","MASS")
install.packages("rlang", "dplyr", "plyr", "candisc", "MASS")
library(rlang)
library(dplyr)
library(plyr)
library(candisc)
library(MASS)
#After installing and loading the library for the MASS pacakge
#output from the discriminant analysis
out2.v2=lda(Species~.,iris)
#Output from the discriminant analysis
out2
lda.scores<-predict(out2.v2,iris)$x   #new coordinates of points after rotation
#Build a table with the new observations
Sepal.Length<-c(4.7,4.8,6.2,5.1,5.6,6.3)
Sepal.Width<-c(3.2,3.2,2.9,2.5,2.8,3.5)
PEtal.Length<-c(1.7,1.6,4.2,3.1,4.1,6)
Petal.Length<-c(1.7,1.6,4.2,3.1,4.1,6)
remove(PEtal.Length)
Petal.Width<-c(0.2,0.2,1.3,1.1,1.3,2.5)
newObs<-as.data.frame(cbind(Sepal.Length,Sepal.Width,Petal.Length,Petal.Width))
View(newObs)
#Predict species of the new observations using discriminant analysis
out2p<-predict(out2.v2,newObs)
scores_unknown<-out2p$x
plot(lda.scores,col=rainbow(3)[iris$Species], asp=1)
points(scores_unknown, pch=19)
install.packages(plsda)
#Testing PLSDA Analysis
Iris.plsda<-PlotPLS2DScore(iris, "pls_score2d_0_", "png", 72, width=NA, 1,2,0.95,0,0)
install.packages("DiscriMiner"")
library(rlang)
library(dplyr)
library(plyr)
library(candisc)
library(MASS)
#load up data for this module
data("USArrests")
head(USArrests)
tail(USArrests)
str(USArrests)
data("iris")
head(iris)
tail(iris)
str(iris)
#Principal Component Analysis (PCA)
PCAoutput1<-princomp(USArrests, cor = T)
#correlation = true or false
#cor = false (covariance matrix) when variables are on the same scale
#cor = true (correlation matrix) when variables are not on the same scale (standardization)
#Output from the PCA
PCAoutput1$loadings     #correlations with the original variables
PCAoutput1$scores       #new coordinate points after rotation
summary(PCAoutput1)     #variance explained by the components
eigen(cor(USArrests))   #eigenvalues
eigen(cor(USArrests))$values/4    #variance explained by eigenvalues
#PCA biplot to visualize the rotated points
biplot(PCAoutput1, choices = c(1,2))
#Discmriminant Analysis
x=lm(cbind(Petal.Length,Sepal.Length,Petal.Width,Sepal.Width)~Species,data = iris)
out2=candisc(x,term="Species")
#Output from the discriminant analysis
#First - look at the results, including the variance explained by each linear discriminant
#Second - Extract the discriminant function loadings
#Finally - Plot
summary(out2)
out2$structure #discriminant loadings
plot(out2,which=c(1,2), scale=8, var.col="#777777", var.lwd=1,
col=c("red","green","blue"))
install.packages("DiscriMiner")
#Testing PLSDA Analysis - packages from the internet
library(DiscriMiner)
# PLS discriminant analysis specifying number of components = 2
my_pls1 = plsDA(iris[,1:4], iris$Species, autosel=FALSE, comps=2)
my_pls1$confusion
my_pls1$error_rate
#plot circle of correlations
plot(my_pls1)
detach("package:DiscriMiner", unload=TRUE)
remove.packages("DiscriMiner"")
remove.packages("DiscriMiner)
remove.packages("DiscriMiner")
# PLS discriminant analysis with automatic selection of components
my_pls2 = plsDA(iris[,1:4], iris$Species, autosel=TRUE)
# PLS discriminant analysis specifying number of components = 2
my_pls1 = plsDA(iris[,1:4], iris$Species, autosel=FALSE, comps=2)
#Testing PLSDA Analysis - packages from the internet
install.packages("DiscriMiner")
library(DiscriMiner)
# PLS discriminant analysis specifying number of components = 2
my_pls1 = plsDA(iris[,1:4], iris$Species, autosel=FALSE, comps=2)
my_pls1$confusion
my_pls1$error_rate
#plot circle of correlations
plot(my_pls1)
# PLS discriminant analysis with automatic selection of components
my_pls2 = plsDA(iris[,1:4], iris$Species, autosel=TRUE)
my_pls2$confusion
my_pls2$error_rate
# # linear discriminant analysis with learn-test validation
learning = c(1:40, 51:90, 101:140)
testing = c(41:50, 91:100, 141:150)
my_pls3 = plsDA(iris[,1:4], iris$Species, validation="learntest",
learn=learning, test=testing)
my_pls3$confusion
my_pls3$error_rate
plot(my_pls2)
plot(my_pls3)
